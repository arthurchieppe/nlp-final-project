# NLP Final Project: Educator

Video link: https://youtu.be/v4YSbqlLlBg

The goal of this project is to demonstrate how to effectively use SpaCy’s pre-trained embeddings to build a deep learning pipeline for sentiment classification, offering a practical approach to leveraging NLP models for text analysis tasks. Additionally, the project compares different SpaCy models to evaluate their performance and effectiveness in this context.

The video begins by exploring what SpaCy is, its core capabilities (such as tokenization, named entity recognition, and lemmatization), and how it streamlines NLP workflows. Then, it walks through a hands-on example in a Jupyter Notebook, where text is preprocessed, embeddings are extracted, and a simple neural network is trained using PyTorch for sentiment classification.

By the end, you’ll understand:
* How SpaCy embeddings work and their different sizes.
* Why we use techniques like mean pooling for embedding aggregation.
* How to implement and train a PyTorch model with binary cross-entropy and Adam optimizer.

Whether you’re new to NLP or looking to combine SpaCy with deep learning techniques, this tutorial offers practical insights to help you get started.

Check out the Jupyter Notebook used in this video: https://github.com/arthurchieppe/nlp-final-project/blob/main/main.ipynb

Unfortunately, the link to the Jupyter Notebook couldn’t be included in the YouTube description, as YouTube requires facial verification to add hyperlinks, and the approval process takes some time.

Author: Arthur Gomes Chieppe
